import json
import math
import os
import random
import subprocess
from dask.distributed import Client, as_completed
import fs.copy
from fs.multifs import MultiFS
import fs.path
from fs.tempfs import TempFS
import tqdm

from b1k_pipeline.utils import ParallelZipFS, PipelineFS, TMP_DIR, launch_cluster

WORKER_COUNT = 4
BATCH_SIZE = 1

ids = {
    "dhkkfo",
    "nfuxzd",
    "lgopij",
    "yhurut",
    "gfxrnj",
    "swytaw",
    "dtjmai",
    "effbnc",
    "exzsal",
    "fxrsyi",
    "fyrkzs",
    "jdijek",
    "qwoqqr",
    "rhohgs",
    "sfvswx",
    "sstojv",
    "uobdoq",
    "uzgibd",
    "zycgen",
    "ecqxgd",
    "nigfha",
    "lymciz",
    "mxsliu",
    "rxscji",
    "xtqbuf",
    "dpxnlc",
    "hvlkjx",
    "cwkvib",
    "dhfqid",
    "eyedvd",
    "xnjqix",
    "adciys",
    "ajzltc",
    "aspeds",
    "belcml",
    "bexgtn",
    "bnobdx",
    "byzaxy",
    "ckxwea",
    "cypjlv",
    "dalyim",
    "eawgwj",
    "eipwho",
    "fedafr",
    "feuaak",
    "fiarri",
    "fwdfeg",
    "hitnkv",
    "hpqjug",
    "hynhgz",
    "jblalf",
    "jfvjep",
    "jhtxxh",
    "jpvcjv",
    "kasebx",
    "kdkrov",
    "kthvrl",
    "lgaxzt",
    "mspdar",
    "nkkhbn",
    "npuuir",
    "oyidja",
    "pihjqa",
    "qzodht",
    "rbnyxi",
    "rlwpcd",
    "sqqahm",
    "szgdpc",
    "tvtive",
    "tyczoo",
    "vccsrl",
    "wryghu",
    "wtepsx",
    "xplzbo",
    "xpnlup",
    "pbvpua",
    "uftzyo",
    "bdhvnt",
    "lsmlzi",
    "wlilma",
    "qixpto",
    "gqwnfv",
    "xcppkc",
    "ouhqnw",
    "ttxunv",
    "hdbsog",
    "mdtkkv",
    "ocjcgp",
    "causya",
    "cdmmwy",
    "hhlmbi",
    "libote",
    "msfzpz",
    "sxlklf",
    "uartvl",
    "ylrxhe",
    "mmbavt",
    "ncbsee",
    "heuzgu",
    "rclizj",
    "qfvqfm",
    "lbcxwi",
    "zndohl",
    "sfkezf",
    "xkixrg",
    "ztripg",
    "ooyqcr",
    "jeqtzg",
    "cvdbum",
    "gklybu",
    "hacehh",
    "jwxbpa",
    "qhnpmc",
    "qlxhhh",
    "uzkxtz",
    "yegrkf",
    "nsxhvs",
    "ovjhuf",
    "cqdioi",
    "xevdnl",
    "kxwgoo",
    "cjmtvq",
    "phimqa",
    "loduxu",
    "ckkwmj",
    "dkxddg",
    "fgizgn",
    "ibhhfj",
    "nbhcgu",
    "nhzrei",
    "rixzrk",
    "rypdvd",
    "siksnl",
    "skamgp",
    "xjdyon",
    "ykuftq",
    "oyqdtz",
    "fvkdos",
    "cfdond",
    "gqemcq",
    "dhseui",
    "lfjmos",
    "hfclfn",
    "lspxjq",
    "xdahvv",
    "ofasfw",
    "yufawg",
    "ifqdxn",
    "vxxcvg",
    "xmxvml",
    "qmdgct",
    "hkdsla",
    "ceaeqf",
    "qornxa",
    "bpwjxr",
    "iwwpsf",
    "uyixwc",
    "qxnzpx",
    "fzhcdb",
    "zhsjcs",
    "gamkbo",
    "ngcvaw",
    "ztyxyi",
    "aewpzn",
    "cprjvq",
    "hzspwg",
    "jpzusm",
    "mhndon",
    "sfbdjn",
    "snvhlz",
    "vycozd",
    "bfaqfe",
    "oxknkz",
    "zdxagk",
    "nawrfs",
    "egpkea",
    "yzeuqo",
    "qwthua",
    "oywwzz",
    "fxnjfr",
    "arryyl",
    "krgqwl",
    "lwsgzd",
    "aeslmf",
    "dhgtvg",
    "qvpthd",
    "nuzkuf",
    "wbnkfk",
    "jvnqly",
    "luhnej",
    "vlurir",
    "lulzdz",
    "gcyvrx",
    "ycgxwb",
    "lkbvad",
    "wengzf",
    "acsllv",
    "bnrvcs",
    "bpxhso",
    "bqpmsv",
    "busiti",
    "crlhmi",
    "dlvall",
    "gejwoi",
    "gkakwk",
    "gqtsam",
    "hjrnct",
    "ifgcmr",
    "iuydyz",
    "jdwvyt",
    "jnjtrl",
    "kfzxah",
    "kijnrj",
    "lvuvbf",
    "mefezc",
    "miivhi",
    "mlnuza",
    "mxhrcl",
    "ociqav",
    "pjaljg",
    "qdnmwg",
    "sjwgfn",
    "vxqpnm",
    "vyfehw",
    "waousd",
    "wcqjew",
    "zdeyzf",
    "nftsal",
    "lrjoro",
    "aysfhf",
    "oqyoos",
    "gjgwvi",
    "hjjeeh",
    "llexze",
    "pvxfot",
    "quzmfw",
    "bzisss",
    "vjbldp",
    "qsdqik",
    "yprkek",
    "bnekjp",
    "rsvypp",
    "ykfkyq",
    "hazvbh",
    "rwnakn",
    "omknho",
    "adxzhe",
    "wigtue",
    "owqbsb",
    "cydfkt",
    "ahtzhp",
    "icvmix",
    "bsgybx",
    "deudkt",
    "xifive",
    "xjzyfc",
    "dhnxww",
    "ehnmxj",
    "fapsrj",
    "jgethp",
    "kewbyf",
    "kitxam",
    "lgxhsc",
    "ntgftr",
    "ppdqbj",
    "ppzttc",
    "waqrdy",
    "yiamah",
    "yxaapv",
    "zsrpiu",
    "lgxfyv",
    "tmjxno",
    "xdhysb",
    "fjpams",
    "gcixra",
    "yoxfyu",
    "zfvhus",
    "jjlfla",
    "bzsxgw",
    "ruryqd",
    "wvhmww",
    "guobeq",
    "jaypjo",
    "xdxqxj",
    "jgyqpd",
    "fhfqys",
    "vbiqcq",
    "xfqatj",
    "csvdbe",
    "wsasmm",
    "barzwx",
    "ankfvi",
    "bbewjo",
    "mbrlge",
    "ompiss",
    "tsyims",
    "tzbnmh",
    "wmkwhg",
    "ihnfbi",
    "skbcqq",
    "vhglly",
    "ygrtaz",
    "aewthq",
    "akfjxx",
    "amhlqh",
    "aynjhg",
    "bgxzec",
    "dbprwc",
    "dnqekb",
    "efkgcw",
    "eixyyn",
    "eozsdg",
    "fhdyrj",
    "fkpaie",
    "haewxp",
    "iawoof",
    "ihrjrb",
    "itoeew",
    "ivbrtz",
    "ivuveo",
    "iwfvwf",
    "kkjiko",
    "kkmkbd",
    "ksgizx",
    "lixwwc",
    "lkomhp",
    "luhkiz",
    "molqhs",
    "mtetqm",
    "nbuspz",
    "nhodax",
    "nikfgd",
    "nmhxfz",
    "nrjump",
    "ntedfx",
    "odmjdd",
    "pjinwe",
    "pkkgzc",
    "pyilfa",
    "qbxfmv",
    "qtfzeq",
    "qyuyjr",
    "spppps",
    "tgrsui",
    "uakqei",
    "ujodgo",
    "uumkbl",
    "vitdwc",
    "vjqzwa",
    "vtjwof",
    "wgcgia",
    "wqgndf",
    "xfjmld",
    "xtdcau",
    "ypdfrp",
    "zpddxu",
    "csanbr",
    "ekjpdj",
    "hnlivs",
    "iadlti",
    "ieoasd",
    "kiiamx",
    "hldhxl",
    "hdcpqg",
    "otyngn",
    "wyojnz",
    "svkdji",
    "yowyst",
    "tnjpsf",
    "trtrsl",
    "uaijua",
    "ukayce",
    "xstykf",
    "duugbb",
    "nuoypc",
    "dafdgk",
    "fjytro",
    "hmzafz",
    "injdmj",
    "tqyiso",
    "ueagnt",
    "ugqdao",
    "dhdhul",
    "kydilb",
    "wdpcmk",
    "fsinsu",
    "chjetk",
    "fbfmwt",
    "kvgaar",
    "obuxbe",
    "ozrwwk",
    "pkfydm",
    "sthkfz",
    "tfzijn",
    "urqzec",
    "uvzmss",
    "vqtkwq",
    "wfryvm",
    "cjsbft",
    "mgbeah",
    "oxivmf",
    "szzjzd",
    "vghfkh",
    "bupgpj",
    "tukaoq",
    "nedrsh",
    "vsxhsv",
    "gswpdr",
    "hamffy",
    "xbkwbi",
    "fsfsas",
    "gnzegv",
    "lpanoc",
    "vicaqs",
    "upfssc",
    "vxtjjn",
    "gzcqwx",
    "nbctrk",
    "saujjl",
    "vlplhs",
    "azoiaq",
    "dcleem",
    "fuzmdd",
    "grrcna",
    "gxiqbw",
    "lfnbhc",
    "oshwps",
    "yvhmex",
    "xixblr",
    "kdlbbq",
    "dhwlaw",
    "kohria",
    "qjhauf",
    "sbvksi",
    "vnvmkx",
    "bsdexp",
    "cpozxi",
    "kccqwj",
    "oxfzfe",
    "tfzfam",
    "vckahe",
    "wopjex",
    "zdvgol",
    "foaehs",
    "jlalfc",
    "mvrhya",
    "apybok",
    "iejmzf",
    "qwtyqj",
    "tgodzn",
    "vnmcfg",
    "ykvekt",
    "iyrrna",
    "krarex",
    "krfzqk",
    "aefcem",
    "cdzyew",
    "cjmezk",
    "djgllo",
    "dnvpag",
    "eahqyq",
    "fkosow",
    "gilsji",
    "glzckq",
    "gsgutn",
    "gvnfgj",
    "gxajos",
    "hqdnjz",
    "hxsyxo",
    "ifzxzj",
    "jlawet",
    "leazin",
    "mcukuh",
    "mdojox",
    "pdmzhv",
    "rbqckd",
    "rteihy",
    "uknjdm",
    "vasiit",
    "wklill",
    "wkxtxh",
    "xkqkbf",
    "zotrbg",
    "avotsj",
    "coqeme",
    "glwebh",
    "gsxbym",
    "hbjdlb",
    "hjxczh",
    "huwhjg",
    "hvlfig",
    "iaaiyi",
    "incirm",
    "jpcflq",
    "mhhoga",
    "mkdcha",
    "mmegts",
    "spopfj",
    "thkphg",
    "tkgsho",
    "txcjux",
    "uekqey",
    "vxbtax",
    "wbwmcs",
    "xzcnjq",
    "yqtlhy",
    "zcmnji",
    "zsddtq",
    "mkstwr",
    "drevku",
    "aegxpb",
    "atgnsc",
    "bbduix",
    "bedkqu",
    "cvyops",
    "dfjcsi",
    "dwspgo",
    "dxnzuk",
    "eqhgiy",
    "euqzpy",
    "gopbrh",
    "hkwtnf",
    "hliauj",
    "htyvuz",
    "icpews",
    "ipbgrw",
    "jdddsr",
    "jpwsrp",
    "kjeudr",
    "mawxva",
    "mdmwcs",
    "meetii",
    "nodcpg",
    "nuqzjs",
    "pqsamn",
    "qebiei",
    "rfegnv",
    "rfigof",
    "rusmlm",
    "rwotxo",
    "saenda",
    "sakwru",
    "stqkvx",
    "szsudo",
    "tjrbxv",
    "toreid",
    "twknia",
    "uuypot",
    "vmbzmm",
    "wltgjn",
    "wmuysk",
    "xfduug",
    "ysdoep",
    "zaziny",
    "zwekzu",
    "hbsbwt",
    "ykysuc",
    "bojwlu",
    "xixlzr",
    "yjmnej",
    "dobgmu",
    "jgyzhv",
    "mrgspe",
    "omeuop",
    "xusefg",
    "ynwamu",
    "zgzvcv",
    "ziomqg",
    "ackxiy",
    "lzdzkk",
    "bbpraa",
    "cdteyb",
    "edfzlt",
    "elwfms",
    "evaida",
    "ewgotr",
    "ggpnlr",
    "gypzlg",
    "igyuko",
    "imsnkt",
    "kttdbu",
    "ktuvuo",
    "kuiiai",
    "lvqgvn",
    "nfoydb",
    "onbiqg",
    "ptciim",
    "qbejli",
    "slscza",
    "szjfpb",
    "uwtdng",
    "vcwsbm",
    "wvztiw",
    "ybhepe",
    "zbridw",
    "msaevo",
    "jpduev",
    "xiwkwz",
    "gtwngf",
    "hlzfxw",
    "vjdkci",
    "zuctnl",
    "vqtevv",
    "aakcyj",
    "adiwil",
    "akusda",
    "bnored",
    "bovcqx",
    "cmdagy",
    "euzudc",
    "exasdr",
    "ezsdil",
    "ggbdlq",
    "hxccge",
    "jzmrdd",
    "kxovsj",
    "oadvet",
    "ovoceo",
    "vxmzmq",
    "yfzibn",
    "pobfpe",
    "vmajcm",
    "ahbhsd",
}


def run_on_batch(dataset_path, batch, mode):
    if mode == "ray":
        script = "b1k_pipeline.usd_conversion.generate_fillable_volumes_process_ray"
    elif mode == "dip":
        script = "b1k_pipeline.usd_conversion.generate_fillable_volumes_process_dip"
    else:
        raise ValueError(f"Unknown mode: {mode}. Choose either ray or dip.")
    python_cmd = ["python", "-m", script, dataset_path] + batch
    cmd = ["micromamba", "run", "-n", "omnigibson", "/bin/bash", "-c", "source /isaac-sim/setup_conda_env.sh && " + " ".join(python_cmd)]
    obj = batch[0][:-1].split("/")[-1]
    with open(f"/scr/ig_pipeline/logs/{obj}.log", "w") as f, open(f"/scr/ig_pipeline/logs/{obj}.err", "w") as ferr:
        return subprocess.run(cmd, stdout=f, stderr=ferr, check=True, cwd="/scr/ig_pipeline")


def main():
    failed_objects = set()
    with PipelineFS() as pipeline_fs, \
         ParallelZipFS("objects_usd.zip") as objects_fs, \
         ParallelZipFS("metadata.zip") as metadata_fs, \
         ParallelZipFS("systems.zip") as systems_fs, \
         TempFS(temp_dir=str(TMP_DIR)) as dataset_fs:
        # with ParallelZipFS("fillable_volumes.zip", write=True) as out_fs:
        with pipeline_fs.makedirs("artifacts/parallels/fillable_volumes", recreate=True) as out_fs:
            # Copy everything over to the dataset FS
            print("Copying input to dataset fs...")
            fs.copy.copy_fs(metadata_fs, dataset_fs)
            fs.copy.copy_fs(systems_fs, dataset_fs)
            objdir_glob = list(objects_fs.glob("objects/*/*/"))
            for item in tqdm.tqdm(objdir_glob):
                if fs.path.parts(item.path)[-1] not in ids:
                    continue
                fs.copy.copy_fs(objects_fs.opendir(item.path), dataset_fs.makedirs(item.path))

            print("Launching cluster...")
            dask_client = launch_cluster(WORKER_COUNT)

            # Start the batched run
            object_glob = [x.path for x in dataset_fs.glob("objects/*/*/")]
            print("Queueing batches.")
            print("Total count: ", len(object_glob))

            # Make sure workers don't idle by reducing batch size when possible.
            batch_size = min(BATCH_SIZE, math.ceil(len(object_glob) / WORKER_COUNT))

            futures = {}
            for start in range(0, len(object_glob), batch_size):
                end = start + batch_size
                batch = object_glob[start:end]

                # First the logic for the ray method
                ray_outputs = [fs.path.join(x, "fillable_ray.obj") for x in batch]
                ray_remaining = list(zip(*[(x, y) for x, y in zip(batch, ray_outputs) if not out_fs.exists(y)]))
                if ray_remaining:
                    ray_batch, ray_outputs = ray_remaining
                    worker_future = dask_client.submit(
                        run_on_batch,
                        dataset_fs.getsyspath("/"),
                        list(ray_batch),
                        "ray",
                        pure=False)
                    futures[worker_future] = list(ray_outputs)

                # Then the dip method.
                dip_outputs = [fs.path.join(x, "fillable_dip.obj") for x in batch]
                dip_remaining = list(zip(*[(x, y) for x, y in zip(batch, dip_outputs) if not out_fs.exists(y)]))
                if dip_remaining:
                    dip_batch, dip_outputs = dip_remaining
                    worker_future = dask_client.submit(
                        run_on_batch,
                        dataset_fs.getsyspath("/"),
                        list(dip_batch),
                        "dip",
                        pure=False)
                    futures[worker_future] = list(dip_outputs)

            # Wait for all the workers to finish
            print("Queued all batches. Waiting for them to finish...")
            logs = []
            for future in tqdm.tqdm(as_completed(futures.keys()), total=len(futures)):
                # Check the batch results.
                batch = futures[future]
                if future.exception():
                    e = future.exception()
                    # logs.append({"stdout": e.stdout.decode("utf-8"), "stderr": e.stderr.decode("utf-8")})
                    print(e)
                else:
                    out = future.result()
                    # logs.append({"stdout": out.stdout.decode("utf-8"), "stderr": out.stderr.decode("utf-8")})

                # Copy the object to the output fs
                for item in batch:
                    dirpath = fs.path.dirname(item)
                    basename = fs.path.basename(item)
                    dataset_dir = dataset_fs.opendir(dirpath)
                    if dataset_dir.exists(basename):
                        fs.copy.copy_file(dataset_dir, basename, out_fs.makedirs(dirpath, recreate=True), basename)

            # Finish up.
            usd_glob = [x.path for x in dataset_fs.glob("objects/*/*/*.obj")]
            print(f"Done processing. Added {len(usd_glob)} objects. Archiving things now.")

        # Save the logs
        with pipeline_fs.pipeline_output().open("generate_fillable_volumes_flat.json", "w") as f:
            json.dump({
                "success": len(failed_objects) == 0,
                "failed_objects": sorted(failed_objects),
                "logs": logs,
            }, f)

if __name__ == "__main__":
    main()
