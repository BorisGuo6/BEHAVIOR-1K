{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "# Define the pattern to match the files\n",
    "pattern = r'D:\\BEHAVIOR-1K\\asset_pipeline\\cad\\*\\*\\artifacts\\replaced_bad_objects.json'\n",
    "\n",
    "# Initialize an empty dictionary to hold the merged contents\n",
    "merged_list = []\n",
    "\n",
    "# Find all files matching the pattern\n",
    "file_paths = glob.glob(pattern)\n",
    "\n",
    "# Iterate over each file and merge its contents into the dictionary\n",
    "for file_path in file_paths:\n",
    "  target = \"/\".join(pathlib.Path(file_path).parts[-4:-2])\n",
    "  with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    for model, instances in data.items():\n",
    "      for instance_id, instance in instances.items():\n",
    "        merged_list.append(((target, model, instance_id), instance))\n",
    "\n",
    "metadata, infos = zip(*merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['original_transform', 'calculated_transform', 'current_transform', 'original_world_bb', 'computed_world_bb', 'current_world_bb', 'original_lowbb', 'current_lowbb'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inventory so that we can find out the category of each model ID\n",
    "with open(r'D:\\BEHAVIOR-1K\\asset_pipeline\\artifacts\\pipeline\\object_inventory.json', 'r') as file:\n",
    "  inventory = json.load(file)\n",
    "\n",
    "category_by_model_id = {entry.split(\"-\")[1]: entry.split(\"-\")[0] for entry in inventory[\"providers\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_size_differences(extract_current_value, extract_baseline_value, subtract_values, reporting_threshold):\n",
    "  current_values = np.array([extract_current_value(info) for info in infos])\n",
    "  baseline_values = np.array([extract_baseline_value(info) for info in infos])\n",
    "  value_diffs = subtract_values(current_values, baseline_values)\n",
    "\n",
    "  # Flatten the world bb size differences and describe the statistics\n",
    "  print(\"Stats:\")\n",
    "  print(\"  Shape\", value_diffs.shape)\n",
    "  print(\"  Mean\", np.mean(value_diffs))\n",
    "  print(\"  Std\", np.std(value_diffs))\n",
    "  print(\"  Min\", np.min(value_diffs))\n",
    "  print(\"  Max\", np.max(value_diffs))\n",
    "\n",
    "  # Print the value of each percentile\n",
    "  for i in range(0, 101, 10):\n",
    "    print(f'  {i}th percentile: {np.percentile(value_diffs, i)}')\n",
    "\n",
    "  # How many items contain any deltas that are greater than 10mm apart?\n",
    "  bad_items = value_diffs > reporting_threshold\n",
    "  bad_item_indices = np.where(bad_items)[0]\n",
    "  bad_item_metas = [metadata[i] for i in bad_item_indices]\n",
    "  bad_item_infos = [infos[i] for i in bad_item_indices]\n",
    "  bad_items = list(zip(bad_item_metas, bad_item_infos))\n",
    "  print(\"\\nTotal count of bad items:\", len(bad_items))\n",
    "\n",
    "  # Group those by target\n",
    "  bad_items_by_target = defaultdict(list)\n",
    "  for meta, info in bad_items:\n",
    "    target = meta[0]\n",
    "    dist = subtract_values(extract_current_value(info), extract_baseline_value(info))\n",
    "    bad_items_by_target[target].append((meta, dist))\n",
    "\n",
    "  # Print each bad item per target sorted by how bad it is\n",
    "  for target, bad_items in bad_items_by_target.items():\n",
    "    print()\n",
    "    print(target)\n",
    "    bad_items.sort(key=lambda x: x[1], reverse=True)\n",
    "    for meta, dist in bad_items:\n",
    "      model_id = meta[1]\n",
    "      instance = meta[2]\n",
    "      category = category_by_model_id.get(model_id, \"Unknown\")\n",
    "      print(f'{category}-{model_id}-{instance}: {dist:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "  Shape (1486,)\n",
      "  Mean 0.7387161116300008\n",
      "  Std 3.980667794750501\n",
      "  Min 0.0\n",
      "  Max 96.3349609375\n",
      "  0th percentile: 0.0\n",
      "  10th percentile: 2.276897430419922e-05\n",
      "  20th percentile: 6.103515625e-05\n",
      "  30th percentile: 0.0001220703125\n",
      "  40th percentile: 0.000244140625\n",
      "  50th percentile: 0.00048828125\n",
      "  60th percentile: 0.0009765625\n",
      "  70th percentile: 0.0106201171875\n",
      "  80th percentile: 0.21435546875\n",
      "  90th percentile: 1.4149169921875\n",
      "  100th percentile: 96.3349609375\n",
      "\n",
      "Total count of bad items: 25\n",
      "\n",
      "scenes/Beechwood_0_garden\n",
      "top_cabinet-fqhdne-0: 27.9336\n",
      "fridge-dszchb-0: 14.1367\n",
      "\n",
      "scenes/Beechwood_0_int\n",
      "countertop-tpuwys-1: 96.3350\n",
      "top_cabinet-fqhdne-0: 27.9326\n",
      "fridge-dszchb-0: 14.1362\n",
      "\n",
      "scenes/Beechwood_1_int\n",
      "top_cabinet-fqhdne-0: 11.7798\n",
      "\n",
      "scenes/Benevolence_1_int\n",
      "top_cabinet-lsyzkh-0: 10.1700\n",
      "\n",
      "scenes/Pomaria_0_int\n",
      "shelf-vgzdul-0: 14.8743\n",
      "shelf-vgzdul-1: 12.5293\n",
      "\n",
      "scenes/Pomaria_1_int\n",
      "top_cabinet-fqhdne-0: 25.0264\n",
      "\n",
      "scenes/Rs_garden\n",
      "microwave-abzvij-0: 11.4700\n",
      "\n",
      "scenes/Rs_int\n",
      "microwave-abzvij-0: 11.4700\n",
      "\n",
      "scenes/Wainscott_0_garden\n",
      "top_cabinet-fqhdne-2: 29.5088\n",
      "top_cabinet-fqhdne-1: 29.5078\n",
      "top_cabinet-fqhdne-0: 20.4766\n",
      "top_cabinet-lsyzkh-1: 16.0634\n",
      "fridge-dszchb-0: 15.5083\n",
      "\n",
      "scenes/Wainscott_0_int\n",
      "top_cabinet-fqhdne-1: 29.5098\n",
      "top_cabinet-fqhdne-2: 29.5093\n",
      "top_cabinet-fqhdne-0: 20.4756\n",
      "top_cabinet-lsyzkh-1: 16.0632\n",
      "fridge-dszchb-0: 15.5068\n",
      "\n",
      "scenes/Wainscott_1_int\n",
      "top_cabinet-fqhdne-0: 49.5376\n",
      "top_cabinet-fqhdne-1: 39.0773\n",
      "top_cabinet-fqhdne-2: 28.2988\n"
     ]
    }
   ],
   "source": [
    "# Run for sizes\n",
    "current_size_extractor = lambda info: np.array(info['current_world_bb'][1]) - np.array(info['current_world_bb'][0])\n",
    "baseline_size_extractor = lambda info: np.array(info['original_world_bb'][1]) - np.array(info['original_world_bb'][0])\n",
    "subtract_values = lambda current, baseline: np.max(np.abs(current - baseline), axis=-1)\n",
    "extract_size_differences(current_size_extractor, baseline_size_extractor, subtract_values, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "  Shape (1486,)\n",
      "  Mean 0.18648382878961345\n",
      "  Std 0.9967486106489379\n",
      "  Min 0.0\n",
      "  Max 24.083740234375\n",
      "  0th percentile: 0.0\n",
      "  10th percentile: 1.1920928955078125e-05\n",
      "  20th percentile: 4.57763671875e-05\n",
      "  30th percentile: 0.0001220703125\n",
      "  40th percentile: 0.0001361370086669922\n",
      "  50th percentile: 0.000244140625\n",
      "  60th percentile: 0.00048828125\n",
      "  70th percentile: 0.001953125\n",
      "  80th percentile: 0.05804443359375\n",
      "  90th percentile: 0.360626220703125\n",
      "  100th percentile: 24.083740234375\n",
      "\n",
      "Total count of bad items: 2\n",
      "\n",
      "scenes/Beechwood_0_int\n",
      "countertop-tpuwys-1: 24.0837\n",
      "\n",
      "scenes/Wainscott_1_int\n",
      "top_cabinet-fqhdne-0: 12.3848\n"
     ]
    }
   ],
   "source": [
    "# Now do the same for centers\n",
    "current_center_extractor = lambda info: np.array(info['current_world_bb'][1]) + np.array(info['current_world_bb'][0]) / 2.\n",
    "baseline_center_extractor = lambda info: np.array(info['original_world_bb'][1]) + np.array(info['original_world_bb'][0]) / 2.\n",
    "subtract_values = lambda current, baseline: np.max(np.abs(current - baseline), axis=-1)\n",
    "extract_size_differences(current_center_extractor, baseline_center_extractor, subtract_values, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "  Shape (1486,)\n",
      "  Mean 0.0027136679440227995\n",
      "  Std 0.016339414803300166\n",
      "  Min 0.0\n",
      "  Max 0.3195149144442973\n",
      "  0th percentile: 0.0\n",
      "  10th percentile: 6.376479618472306e-14\n",
      "  20th percentile: 4.3820510726244904e-13\n",
      "  30th percentile: 3.413470242769857e-11\n",
      "  40th percentile: 4.040315682753605e-09\n",
      "  50th percentile: 3.452541863470996e-08\n",
      "  60th percentile: 3.3337107951295256e-06\n",
      "  70th percentile: 5.122643989398504e-06\n",
      "  80th percentile: 1.104036237651266e-05\n",
      "  90th percentile: 0.0015844999831939092\n",
      "  100th percentile: 0.3195149144442973\n",
      "\n",
      "Total count of bad items: 0\n"
     ]
    }
   ],
   "source": [
    "# Finally lets do it for the rotation matrix\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "_EPS = np.finfo(float).eps * 4.0\n",
    "def get_rotation_from_transform(matrix):\n",
    "    M = np.array(matrix, dtype=np.float64).T\n",
    "    if abs(M[3, 3]) < _EPS:\n",
    "        raise ValueError(\"M[3, 3] is zero\")\n",
    "    M /= M[3, 3]\n",
    "    P = M.copy()\n",
    "    P[:, 3] = 0.0, 0.0, 0.0, 1.0\n",
    "    if not np.linalg.det(P):\n",
    "        raise ValueError(\"matrix is singular\")\n",
    "\n",
    "    scale = np.zeros((3,))\n",
    "    shear = [0.0, 0.0, 0.0]\n",
    "\n",
    "    if any(abs(M[:3, 3]) > _EPS):\n",
    "        M[:, 3] = 0.0, 0.0, 0.0, 1.0\n",
    "\n",
    "    M[3, :3] = 0.0\n",
    "\n",
    "    row = M[:3, :3].copy()\n",
    "    scale[0] = np.linalg.norm(row[0])\n",
    "    row[0] /= scale[0]\n",
    "    shear[0] = np.dot(row[0], row[1])\n",
    "    row[1] -= row[0] * shear[0]\n",
    "    scale[1] = np.linalg.norm(row[1])\n",
    "    row[1] /= scale[1]\n",
    "    shear[0] /= scale[1]\n",
    "    shear[1] = np.dot(row[0], row[2])\n",
    "    row[2] -= row[0] * shear[1]\n",
    "    shear[2] = np.dot(row[1], row[2])\n",
    "    row[2] -= row[1] * shear[2]\n",
    "    scale[2] = np.linalg.norm(row[2])\n",
    "    row[2] /= scale[2]\n",
    "    shear[1:] /= scale[2]\n",
    "\n",
    "    if np.dot(row[0], np.cross(row[1], row[2])) < 0:\n",
    "        np.negative(scale, scale)\n",
    "        np.negative(row, row)\n",
    "\n",
    "    return row.T, scale\n",
    "\n",
    "current_rotation_extractor = lambda info: get_rotation_from_transform(info['current_transform'])[0]\n",
    "baseline_rotation_extractor = lambda info: get_rotation_from_transform(info['original_transform'])[0]\n",
    "subtract_values = lambda current, baseline: np.array([np.rad2deg((R.from_matrix(b).inv() * R.from_matrix(c)).magnitude()) for b, c in zip(baseline, current)])\n",
    "extract_size_differences(current_rotation_extractor, baseline_rotation_extractor, subtract_values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('scenes/Beechwood_0_garden', 'dszchb', '0'), 7.068359375),\n",
       " (('scenes/Beechwood_0_int', 'dszchb', '0'), 7.068115234375),\n",
       " (('scenes/Wainscott_0_garden', 'dszchb', '0'), 7.75439453125),\n",
       " (('scenes/Wainscott_0_int', 'dszchb', '0'), 7.75390625)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for instances of vgzdul and get their world BB size differences\n",
    "bad_shelf = \"vgzdul\"\n",
    "bad_fridge = \"dszchb\"\n",
    "[(meta, np.max(np.abs(np.array(info['current_world_bb']) - np.array(info[\"original_world_bb\"]))))\n",
    " for meta, info in merged_list if meta[1] == bad_fridge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
